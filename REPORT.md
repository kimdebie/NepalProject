#Final Report

###Kim de Bie (11077379): Programming Project (Minor Programmeren, Universiteit van Amsterdam)

####Introduction
In this final report, I will describe the process of developing my data visualization tool. Firstly, the theory behind the visualization and the reasons for developing it will be discussed. After this, I will discuss how the theoretical underpinnings have informed the visual design of the visualization. Thirdly, I will discuss how the visualization was technically implemented. Throughout the report, I will describe the reasons for implementing both design and visual aspects in the way I did, linking back to the theoretical framework wherever possible, the difficulties I encountered during developing the visualization and the solutions I found to these issues. 

####Theoretical framework
Natural disasters do not only place enormous strain on affected individuals, but also provide a very large challenge to those who aim to provide help. By their very nature, disasters are very messy, unstructured situations, where uncertainty is the rule. In the first days after an emergency hits, it is incredibly difficult for aid workers to identify what help is needed where. However, crowdsourced data from sources such as Twitter or Facebook is increasingly seen as a tool to improve the disaster response. [Researchers]( https://dl.acm.org/citation.cfm?id=2669443) find that there are three important theoretical benefits to crowdsourced data, as compared to conventional data collected by aid organizations. Firstly, crowdsourced data is argued to become available from a larger number of locations: __spatial spread__ is said to be larger. Researchers also claim that the data is available __more quickly__, and that it contains information about a __wider range of topics__. 

Nonetheless, aid organizations are reluctant to make use of crowdsourced data: they believe their conventional data collection mechanisms do the job well enough, and many aid workers are not convinced of the benefits of using crowdsourced data. For this reason, it seems important to place crowdsourced and conventional data in a comparative perspective, and see who is right: the optimistic theorizer or the pessimistic practitioner (or perhaps a bit of both?).  That is exactly what this visualization aims to do. Using both conventional and crowdsourced data collected during the 2015 earthquake in Nepal, data quality is assessed along the three dimensions mentioned above: spatial spread, speed and the spread over different topics. As such, the visualization may improve understanding of the various qualities of different types of data, and how they may be used to make the disaster response better in the future. 


####Designing the visualization
The three most important qualities that crowdsourced data is claimed to have are, as described above, speed, spatial spread and spread over different topics. Therefore, the visualization should especially clarify the differences between conventional and crowdsourced data on these dimensions. Here, I will describe the design of the four elements that I used to display the three data dimensions. 

The first element of the visualization, the __map__ on the homepage, mainly gives insights into the _spatial spread_ of the data. By coloring districts darker when there is more data available (in other words, when data density is higher), it becomes visible which data source provides more information about a district. Although I considered mapping data points to their exact location (so not simply their district), I decided against this: many data points that are applicable to an entire district are only linked to the district capital in my dataset. Therefore, I feel that linking data points exclusively to a district capital would give a false representation of reality, and I have used data density per district as the measure for spatial spread of my data. Buttons are used to swap between conventional and crowdsourced data. In order to say something about the total amount of data that was available (because it would probably make sense to use both data sources together in real disaster environments), a button to display both data sources at once is included. Lastly, a date slider allows the user to select a date to see how many reports were available at that point in time, which gives some initial information about the _speed_ at which data becomes available.  Here, and in all other parts of the visualization where a time element is present, I have chosen to include reports __up to__ the selected date. This because reports that became available earlier are probably still relevant today, and still contribute to the total amount of knowledge about the situation.

On clicking a district on the map, a __grouped bar chart__ appears, which shows the distribution of data over various categories and the two data types. This informs us about the _spread over different topics_ at the district level for both data types. The bar chart, too, includes data up to the point in time selected. I chose to make the spread over different topics insightful by means of a bar chart, because comparing length of the bars is an easy, user-friendly way to understand quantitative differences.

The third main element of the visualization is the __line graph__ on the page ‘data over time’. This element allows the user to explore the total _speed_ at which data becomes available. Whereas the map provides insights into speed per district, the line graph allows the user to explore data cumulatively. Here, too, a line for the combined data is included, again to understand how much we would know if we would use both conventional and crowdsourced data in a given situation. On hovering over the line, the absolute number of reports for each data type becomes visible.

On clicking a point in time on the line graph, again, a __grouped bar chart__ appears. This bar chart is very similar to that on the homepage, only now the total amount of data is displayed, instead of by district only. This, again, informs us about the _spread over different topics_ of both data types: does crowdsourced data indeed provide us information about a wider range of issues? 

Lastly, to put the data in context and to give the user an idea of what she is looking at and why it may be important, a large part of the website I developed contains additional (textual) information about both crowdsourced data and the Nepal earthquake. In addition, I chose to add a few photos to the web page, to increase visual attractiveness and to invite the user to explore the entire website. 


####Technical design: implementing the code
The _data_ used for this visualization comes from two types of situational reports: those built on conventional data and those based on crowdsourced data. The data is stored in csv format, containing rows with variables such as time, location and category of the report. In this section, I will explain how the data is used for the visualization on a technical level. D3.js is the main support library for all elements of the visualization.

The __map__ element builds on a JSON-file that contains the geographical characteristics of the different districts. After loading the map, the data is linked to the districts. Taking into account the selected data type (by clicking on a button) and the selected date (by moving the date slider), the map is colored. The data points for the appropriate date and source are counted, after which the number of reports is linked to a color. The colors are updated every time the user presses a data-type button or moves the date slider. Here, an issue that I encountered was determining the bucket size for each color. At first, all buckets were of equal size, but because a few districts have a lot more data than other districts, a high number of districts ended up in the smallest bucket. Therefore, I chose to adapt the range of the buckets. All buckets except the last are still of equal size, so that the image given is not distorted too much. 

On clicking a district, the __bar chart__ appears. The bar chart inherits information about the selected district and the date, and again the data rows are counted for these variables, splitting them by category. Then, the bars, axes and legend are created on the basis of the counts per category and data type. An issue regarding the design of the bar chart was determining the range of the axes. At first, I chose to implement static axes, to increase comparability. However, because the amount of data varied so much per district, the bars became very small for many of the districts when keeping the axes static across districts, which in fact decreased clarity and comparability. Another factor that led me to make the axes flexible is the fact that only one bar graph is displayed at the time, and not multiple are put next to each other: comparisons within the bar graph are more important than those across bar graphs.

The __multiple line graph__ was rather difficult to implement. Drawing the lines was not so difficult, but implementing a crosshair that would show the amount of data for each line simultaneously (so, hovering over a day gives you information about both data types for that day) proved very challenging using D3.js only. Therefore, after consulting various online resources, I chose to implement the line graph using C3.js, which has this simultaneous crosshair implemented by default. The advantage of this approach was that it turned out to be very easy to implement the line graph with C3.js, however, what is gained in difficulty seems to be lost in flexibility. It was quite difficult (and not always possible) to tweak features of the line graph after I created it. However, the main setback of using C3.js turned out to be its interference with D3.js, which I will discuss below. For the line graph, too, the data is firstly counted, then the counts are converted into arrays which form the basis of the line graph.

The __bar chart__ that appears on clicking a date on the line graph is similar to that on the home page, but now include reports for every district up to the date selected. A large issue that I encountered here is implementing the tooltip as I created it for the bar chart on the homepage, using D3.js. However, it turned out that C3.js blocked the tooltip functionality of D3.js, which made it impossible to implement the tooltip as I had done it before. I tried to work around this problem in two main ways. Firstly, I focused on the C3/D3 scripts themselves, editing these and trying to ‘disable’ the C3 script temporarily. This did not work out, so I chose another route: implementing the tooltip using other tooltip libraries. However, I still encountered the same issues, and therefore I chose to implement a tooltip-like element manually. On hovering over a bar, the amount of reports that that bar contains is now displayed in a static location.

####Shortcomings and future
A first element that could be improved is the tooltip that I implemented on the line graph page. Due to time constraints, I did not manage to display the tooltip in flexible locations, although this would add positively to the visual appearance of the bar graph.

Another element that I could not implement due to the constraints of my dataset is an element that displays the actual text of the different reports. This would have made the visualization more insightful, and would have allowed the user to explore the two datasets more in-depth. 

Lastly, the web page I created only displays the data, but does not analyze it. As a next step for this project, it would be interesting to include some comparative results, either in the form of text or visuals. Analysis of the results is the last step required to answer the question posed by this visualization: how do crowdsourced and conventional disaster data compare, and can crowdsourced data live up to the expectations? 

